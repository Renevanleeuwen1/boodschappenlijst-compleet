{"ast":null,"code":"// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\nimport { APIResource } from \"../core/resource.mjs\";\nimport { loggerFor, toFloat32Array } from \"../internal/utils.mjs\";\nexport class Embeddings extends APIResource {\n  /**\r\n   * Creates an embedding vector representing the input text.\r\n   *\r\n   * @example\r\n   * ```ts\r\n   * const createEmbeddingResponse =\r\n   *   await client.embeddings.create({\r\n   *     input: 'The quick brown fox jumped over the lazy dog',\r\n   *     model: 'text-embedding-3-small',\r\n   *   });\r\n   * ```\r\n   */\n  create(body, options) {\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\n    // No encoding_format specified, defaulting to base64 for performance reasons\n    // See https://github.com/openai/openai-node/pull/1312\n    let encoding_format = hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\n    if (hasUserProvidedEncodingFormat) {\n      loggerFor(this._client).debug('embeddings/user defined encoding_format:', body.encoding_format);\n    }\n    const response = this._client.post('/embeddings', {\n      body: {\n        ...body,\n        encoding_format: encoding_format\n      },\n      ...options\n    });\n    // if the user specified an encoding_format, return the response as-is\n    if (hasUserProvidedEncodingFormat) {\n      return response;\n    }\n    // in this stage, we are sure the user did not specify an encoding_format\n    // and we defaulted to base64 for performance reasons\n    // we are sure then that the response is base64 encoded, let's decode it\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\n    loggerFor(this._client).debug('embeddings/decoding base64 embeddings from base64');\n    return response._thenUnwrap(response => {\n      if (response && response.data) {\n        response.data.forEach(embeddingBase64Obj => {\n          const embeddingBase64Str = embeddingBase64Obj.embedding;\n          embeddingBase64Obj.embedding = toFloat32Array(embeddingBase64Str);\n        });\n      }\n      return response;\n    });\n  }\n}","map":{"version":3,"names":["APIResource","loggerFor","toFloat32Array","Embeddings","create","body","options","hasUserProvidedEncodingFormat","encoding_format","_client","debug","response","post","_thenUnwrap","data","forEach","embeddingBase64Obj","embeddingBase64Str","embedding"],"sources":["C:\\boodschappenlijst\\boodschappenlijst-compleet\\node_modules\\openai\\src\\resources\\embeddings.ts"],"sourcesContent":["// File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.\r\n\r\nimport { APIResource } from '../core/resource';\r\nimport { APIPromise } from '../core/api-promise';\r\nimport { RequestOptions } from '../internal/request-options';\r\nimport { loggerFor, toFloat32Array } from '../internal/utils';\r\n\r\nexport class Embeddings extends APIResource {\r\n  /**\r\n   * Creates an embedding vector representing the input text.\r\n   *\r\n   * @example\r\n   * ```ts\r\n   * const createEmbeddingResponse =\r\n   *   await client.embeddings.create({\r\n   *     input: 'The quick brown fox jumped over the lazy dog',\r\n   *     model: 'text-embedding-3-small',\r\n   *   });\r\n   * ```\r\n   */\r\n  create(body: EmbeddingCreateParams, options?: RequestOptions): APIPromise<CreateEmbeddingResponse> {\r\n    const hasUserProvidedEncodingFormat = !!body.encoding_format;\r\n    // No encoding_format specified, defaulting to base64 for performance reasons\r\n    // See https://github.com/openai/openai-node/pull/1312\r\n    let encoding_format: EmbeddingCreateParams['encoding_format'] =\r\n      hasUserProvidedEncodingFormat ? body.encoding_format : 'base64';\r\n\r\n    if (hasUserProvidedEncodingFormat) {\r\n      loggerFor(this._client).debug('embeddings/user defined encoding_format:', body.encoding_format);\r\n    }\r\n\r\n    const response: APIPromise<CreateEmbeddingResponse> = this._client.post('/embeddings', {\r\n      body: {\r\n        ...body,\r\n        encoding_format: encoding_format as EmbeddingCreateParams['encoding_format'],\r\n      },\r\n      ...options,\r\n    });\r\n\r\n    // if the user specified an encoding_format, return the response as-is\r\n    if (hasUserProvidedEncodingFormat) {\r\n      return response;\r\n    }\r\n\r\n    // in this stage, we are sure the user did not specify an encoding_format\r\n    // and we defaulted to base64 for performance reasons\r\n    // we are sure then that the response is base64 encoded, let's decode it\r\n    // the returned result will be a float32 array since this is OpenAI API's default encoding\r\n    loggerFor(this._client).debug('embeddings/decoding base64 embeddings from base64');\r\n\r\n    return (response as APIPromise<CreateEmbeddingResponse>)._thenUnwrap((response) => {\r\n      if (response && response.data) {\r\n        response.data.forEach((embeddingBase64Obj) => {\r\n          const embeddingBase64Str = embeddingBase64Obj.embedding as unknown as string;\r\n          embeddingBase64Obj.embedding = toFloat32Array(embeddingBase64Str);\r\n        });\r\n      }\r\n\r\n      return response;\r\n    });\r\n  }\r\n}\r\n\r\nexport interface CreateEmbeddingResponse {\r\n  /**\r\n   * The list of embeddings generated by the model.\r\n   */\r\n  data: Array<Embedding>;\r\n\r\n  /**\r\n   * The name of the model used to generate the embedding.\r\n   */\r\n  model: string;\r\n\r\n  /**\r\n   * The object type, which is always \"list\".\r\n   */\r\n  object: 'list';\r\n\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  usage: CreateEmbeddingResponse.Usage;\r\n}\r\n\r\nexport namespace CreateEmbeddingResponse {\r\n  /**\r\n   * The usage information for the request.\r\n   */\r\n  export interface Usage {\r\n    /**\r\n     * The number of tokens used by the prompt.\r\n     */\r\n    prompt_tokens: number;\r\n\r\n    /**\r\n     * The total number of tokens used by the request.\r\n     */\r\n    total_tokens: number;\r\n  }\r\n}\r\n\r\n/**\r\n * Represents an embedding vector returned by embedding endpoint.\r\n */\r\nexport interface Embedding {\r\n  /**\r\n   * The embedding vector, which is a list of floats. The length of vector depends on\r\n   * the model as listed in the\r\n   * [embedding guide](https://platform.openai.com/docs/guides/embeddings).\r\n   */\r\n  embedding: Array<number>;\r\n\r\n  /**\r\n   * The index of the embedding in the list of embeddings.\r\n   */\r\n  index: number;\r\n\r\n  /**\r\n   * The object type, which is always \"embedding\".\r\n   */\r\n  object: 'embedding';\r\n}\r\n\r\nexport type EmbeddingModel = 'text-embedding-ada-002' | 'text-embedding-3-small' | 'text-embedding-3-large';\r\n\r\nexport interface EmbeddingCreateParams {\r\n  /**\r\n   * Input text to embed, encoded as a string or array of tokens. To embed multiple\r\n   * inputs in a single request, pass an array of strings or array of token arrays.\r\n   * The input must not exceed the max input tokens for the model (8192 tokens for\r\n   * all embedding models), cannot be an empty string, and any array must be 2048\r\n   * dimensions or less.\r\n   * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)\r\n   * for counting tokens. In addition to the per-input token limit, all embedding\r\n   * models enforce a maximum of 300,000 tokens summed across all inputs in a single\r\n   * request.\r\n   */\r\n  input: string | Array<string> | Array<number> | Array<Array<number>>;\r\n\r\n  /**\r\n   * ID of the model to use. You can use the\r\n   * [List models](https://platform.openai.com/docs/api-reference/models/list) API to\r\n   * see all of your available models, or see our\r\n   * [Model overview](https://platform.openai.com/docs/models) for descriptions of\r\n   * them.\r\n   */\r\n  model: (string & {}) | EmbeddingModel;\r\n\r\n  /**\r\n   * The number of dimensions the resulting output embeddings should have. Only\r\n   * supported in `text-embedding-3` and later models.\r\n   */\r\n  dimensions?: number;\r\n\r\n  /**\r\n   * The format to return the embeddings in. Can be either `float` or\r\n   * [`base64`](https://pypi.org/project/pybase64/).\r\n   */\r\n  encoding_format?: 'float' | 'base64';\r\n\r\n  /**\r\n   * A unique identifier representing your end-user, which can help OpenAI to monitor\r\n   * and detect abuse.\r\n   * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\r\n   */\r\n  user?: string;\r\n}\r\n\r\nexport declare namespace Embeddings {\r\n  export {\r\n    type CreateEmbeddingResponse as CreateEmbeddingResponse,\r\n    type Embedding as Embedding,\r\n    type EmbeddingModel as EmbeddingModel,\r\n    type EmbeddingCreateParams as EmbeddingCreateParams,\r\n  };\r\n}\r\n"],"mappings":"AAAA;SAESA,WAAW,QAAE;SAGbC,SAAS,EAAEC,cAAc,QAAE;AAEpC,OAAM,MAAOC,UAAW,SAAQH,WAAW;EACzC;;;;;;;;;;;;EAYAI,MAAMA,CAACC,IAA2B,EAAEC,OAAwB;IAC1D,MAAMC,6BAA6B,GAAG,CAAC,CAACF,IAAI,CAACG,eAAe;IAC5D;IACA;IACA,IAAIA,eAAe,GACjBD,6BAA6B,GAAGF,IAAI,CAACG,eAAe,GAAG,QAAQ;IAEjE,IAAID,6BAA6B,EAAE;MACjCN,SAAS,CAAC,IAAI,CAACQ,OAAO,CAAC,CAACC,KAAK,CAAC,0CAA0C,EAAEL,IAAI,CAACG,eAAe,CAAC;IACjG;IAEA,MAAMG,QAAQ,GAAwC,IAAI,CAACF,OAAO,CAACG,IAAI,CAAC,aAAa,EAAE;MACrFP,IAAI,EAAE;QACJ,GAAGA,IAAI;QACPG,eAAe,EAAEA;OAClB;MACD,GAAGF;KACJ,CAAC;IAEF;IACA,IAAIC,6BAA6B,EAAE;MACjC,OAAOI,QAAQ;IACjB;IAEA;IACA;IACA;IACA;IACAV,SAAS,CAAC,IAAI,CAACQ,OAAO,CAAC,CAACC,KAAK,CAAC,mDAAmD,CAAC;IAElF,OAAQC,QAAgD,CAACE,WAAW,CAAEF,QAAQ,IAAI;MAChF,IAAIA,QAAQ,IAAIA,QAAQ,CAACG,IAAI,EAAE;QAC7BH,QAAQ,CAACG,IAAI,CAACC,OAAO,CAAEC,kBAAkB,IAAI;UAC3C,MAAMC,kBAAkB,GAAGD,kBAAkB,CAACE,SAA8B;UAC5EF,kBAAkB,CAACE,SAAS,GAAGhB,cAAc,CAACe,kBAAkB,CAAC;QACnE,CAAC,CAAC;MACJ;MAEA,OAAON,QAAQ;IACjB,CAAC,CAAC;EACJ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}